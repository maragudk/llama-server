services:
  llama-server:
    image: llama-server
    ports:
      - "8080:8080"
    volumes:
      - models:/models

volumes:
  models:
